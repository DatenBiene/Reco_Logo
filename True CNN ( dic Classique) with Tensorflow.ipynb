{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classique sans data aug : 73.6% \n",
    "avec aug 81.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On importe nos données comme d'habitude "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_aug=4\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "\n",
    "imPath = \"Database/All_pictures/\"\n",
    "ls_path = glob(os.path.join(imPath, '*' ))\n",
    "\n",
    "images_base_vide=[]\n",
    "label_nom_vide=[]\n",
    "\n",
    "for file in ls_path: \n",
    "    im = np.array(Image.open(file))[:,:,3]   \n",
    "    images_base_vide+=[im]\n",
    "    label_nom_vide+=[file.split('\\\\')[1].split('_')[0]]   \n",
    "images_base_raw=np.array(images_base_vide)\n",
    "label_nom_raw=np.array(label_nom_vide)\n",
    "\n",
    "def print_exemple_image(num_image,X=images_base_raw,y=label_nom_vide) :\n",
    "    plt.imshow(X[num_image],cmap='Greys')\n",
    "    plt.suptitle(\"Image n°\"+str(num_image)+\" : \"+str(y[num_image]), fontsize=20)\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ramdom_seed_fixée=5\n",
    "\n",
    "def get_split_classique() :\n",
    "    return train_test_split(images_base_raw, label_nom_raw, test_size=0.20, random_state=ramdom_seed_fixée)\n",
    "\n",
    "X_train_classique , X_test_classique , Y_train_classique , Y_test_classique = get_split_classique()\n",
    "\n",
    "label_to_OneHot = {'Deezer':[1,0,0,0],'Messenger':[0,1,0,0],'Facebook':[0,0,1,0],'Tinder':[0,0,0,1]}\n",
    "label_to_num = {'Deezer':0 ,'Messenger':1 ,'Facebook':2,'Tinder':3} \n",
    "num_to_label={0:'Deezer',1:'Messenger' ,2:'Facebook',3:'Tinder'}\n",
    "\n",
    "def transformation_dictionnaire_image(X,Y,data_aug=1,num_pixel_cote=64) : \n",
    "    taille = X.shape[0]\n",
    "    data_base={'image':[], 'data': [], 'label_num' : [],'label_OneHot' : [],'nom_label' :[]}\n",
    "    for i in range(taille) : \n",
    "        im = cv2.resize(X[i], (num_pixel_cote,num_pixel_cote))\n",
    "        name=Y[i]\n",
    "        \n",
    "        for k in range(data_aug):\n",
    "            num_rows, num_cols = im.shape[:2]\n",
    "            rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), k*5, 1)\n",
    "            im_rotation = cv2.warpAffine(im, rotation_matrix, (num_cols, num_rows))\n",
    "        \n",
    "            \n",
    "            data_base['image']+=[im_rotation]\n",
    "            data_base['data']+=[np.ndarray.flatten(im_rotation)]\n",
    "            data_base['label_num']+=[label_to_num[name]]\n",
    "            data_base['label_OneHot']+=[label_to_OneHot[name]]\n",
    "            data_base['nom_label']+=[name]\n",
    "            \n",
    "            \n",
    "    data_base['image']=np.array( data_base['image'])\n",
    "    data_base['data']=np.array(data_base['data'])\n",
    "    data_base['label_num']=np.array(data_base['label_num'])\n",
    "    data_base['label_OneHot']=np.array(data_base['label_OneHot'])\n",
    "    data_base['nom_label']=np.array(data_base['nom_label'])\n",
    "    \n",
    "    return data_base\n",
    "        \n",
    "Train_Classique = transformation_dictionnaire_image(X_train_classique,Y_train_classique,data_aug=num_aug)\n",
    "Test_Classique = transformation_dictionnaire_image(X_test_classique,Y_test_classique)\n",
    "\n",
    "catégories= ['Deezer','Facebook','Messenger','Tinder']\n",
    "\n",
    "X_train_progressif , X_test_progressif , Y_train_progressif , Y_test_progressif = [],[],[],[]\n",
    "\n",
    "for cat in catégories : \n",
    "    imPath = \"Database/\"+cat+\"/\"\n",
    "    ls_path = glob(os.path.join(imPath, '*' ))\n",
    "\n",
    "    taille_train=len(ls_path)-len(ls_path)//5\n",
    "    #Train\n",
    "    for file in ls_path[:taille_train]: \n",
    "        im = np.array(Image.open(file))[:,:,3]   \n",
    "        X_train_progressif+=[im]\n",
    "        Y_train_progressif+=[file.split('\\\\')[1].split('_')[0]]\n",
    "\n",
    "    #Test\n",
    "    for file in ls_path[taille_train:]: \n",
    "        im = np.array(Image.open(file))[:,:,3]   \n",
    "        X_test_progressif+=[im]\n",
    "        Y_test_progressif+=[file.split('\\\\')[1].split('_')[0]]\n",
    "    \n",
    "\n",
    "X_train_progressif=np.array(X_train_progressif)\n",
    "Y_train_progressif=np.array(Y_train_progressif)\n",
    "X_test_progressif=np.array(X_test_progressif)\n",
    "Y_test_progressif=np.array(Y_test_progressif)\n",
    "\n",
    "\n",
    "Train_Progressif = transformation_dictionnaire_image(X_train_progressif,Y_train_progressif,data_aug=num_aug)\n",
    "Test_Progressif = transformation_dictionnaire_image(X_test_progressif,Y_test_progressif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Premier convolutional Layer.\n",
    "filter_size1 = 5          # Filtre de 5 x 5 pixels.\n",
    "num_filters1 = 16         # Il y a ici 16 filtres.\n",
    "\n",
    "# Deuxième convolutional Layer\n",
    "filter_size2 = 5          # Filtre de 5 x 5 pixels.\n",
    "num_filters2 = 36         # Il y a ici 36 filtres .\n",
    "\n",
    "# Couche fully connected \n",
    "fc_size = 128             # Nombre de neuronnes dans la dernière couche "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Train_dic=Train_Classique\n",
    "Test_dic=Test_Classique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Train_dic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f7d656f9678f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Taille du:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"- Training set:\\t\\t{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTrain_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"- Test set:\\t\\t{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTest_dic\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Train_dic' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Taille du:\")\n",
    "print(\"- Training set:\\t\\t{}\".format(Train_dic['image'].shape[0]))\n",
    "print(\"- Test set:\\t\\t{}\".format(Test_dic['image'].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Nombre pixel coté\n",
    "img_size = Train_dic['image'].shape[1]\n",
    "\n",
    "# Nombre de pixel au total\n",
    "img_size_flat = Train_dic['data'].shape[1]\n",
    "\n",
    "# Nombre de pixel longeur et largeur \n",
    "img_shape = Train_dic['image'].shape[1:]\n",
    "\n",
    "# Nombre de classes (si on ajoute de nouveaux logos)\n",
    "num_classes = 4 \n",
    "\n",
    "# Noir et blanc ? 1 si oui \n",
    "num_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3,  figsize=(10,5))\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"Vrai: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"Vrai: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAEvCAYAAACdahL0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwCIiIg5QAhYREXGAErCIiIgD/h8oG5jfy2n/YgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e4528834a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = Train_dic['image'][0:9]\n",
    "cls_vrai = [num_to_label[i] for i in Train_dic['label_num'][0:9]]\n",
    "\n",
    "\n",
    "plot_images(images=images, cls_vrai=cls_vrai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crea_poids(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.05))\n",
    "\n",
    "def nouveau_biais(length):\n",
    "    return tf.Variable(tf.constant(0.05, shape=[length]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_conv_layer(input,              # The previous layer.\n",
    "                   num_input_channels, # Num. channels in prev. layer.\n",
    "                   filter_size,        # Width and height of each filter.\n",
    "                   num_filters,        # Number of filters.\n",
    "                   use_pooling=True):  # Use 2x2 max-pooling.\n",
    "\n",
    "    # Shape of the filter-weights for the convolution.\n",
    "    # This format is determined by the TensorFlow API.\n",
    "    shape = [filter_size, filter_size, num_input_channels, num_filters]\n",
    "\n",
    "    # Create new weights aka. filters with the given shape.\n",
    "    weights = crea_poids(shape=shape)\n",
    "\n",
    "    # Create new biases, one for each filter.\n",
    "    biases = nouveau_biais(length=num_filters)\n",
    "\n",
    "    # Create the TensorFlow operation for convolution.\n",
    "    # Note the strides are set to 1 in all dimensions.\n",
    "    # The first and last stride must always be 1,\n",
    "    # because the first is for the image-number and\n",
    "    # the last is for the input-channel.\n",
    "    # But e.g. strides=[1, 2, 2, 1] would mean that the filter\n",
    "    # is moved 2 pixels across the x- and y-axis of the image.\n",
    "    # The padding is set to 'SAME' which means the input image\n",
    "    # is padded with zeroes so the size of the output is the same.\n",
    "    layer = tf.nn.conv2d(input=input,\n",
    "                         filter=weights,\n",
    "                         strides=[1, 1, 1, 1],\n",
    "                         padding='SAME')\n",
    "\n",
    "    # Add the biases to the results of the convolution.\n",
    "    # A bias-value is added to each filter-channel.\n",
    "    layer += biases\n",
    "\n",
    "    # Use pooling to down-sample the image resolution?\n",
    "    if use_pooling:\n",
    "        # This is 2x2 max-pooling, which means that we\n",
    "        # consider 2x2 windows and select the largest value\n",
    "        # in each window. Then we move 2 pixels to the next window.\n",
    "        layer = tf.nn.max_pool(value=layer,\n",
    "                               ksize=[1, 2, 2, 1],\n",
    "                               strides=[1, 2, 2, 1],\n",
    "                               padding='SAME')\n",
    "\n",
    "    # Rectified Linear Unit (ReLU).\n",
    "    # It calculates max(x, 0) for each input pixel x.\n",
    "    # This adds some non-linearity to the formula and allows us\n",
    "    # to learn more complicated functions.\n",
    "    layer = tf.nn.relu(layer)\n",
    "\n",
    "    # Note that ReLU is normally executed before the pooling,\n",
    "    # but since relu(max_pool(x)) == max_pool(relu(x)) we can\n",
    "    # save 75% of the relu-operations by max-pooling first.\n",
    "\n",
    "    # We return both the resulting layer and the filter-weights\n",
    "    # because we will plot the weights later.\n",
    "    return layer, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "    \n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_fc_layer(input,          # The previous layer.\n",
    "                 num_inputs,     # Num. inputs from prev. layer.\n",
    "                 num_outputs,    # Num. outputs.\n",
    "                 use_relu=True): # Use Rectified Linear Unit (ReLU)?\n",
    "\n",
    "    # Create new weights and biases.\n",
    "    weights = crea_poids(shape=[num_inputs, num_outputs])\n",
    "    biases = nouveau_biais(length=num_outputs)\n",
    "\n",
    "    # Calculate the layer as the matrix multiplication of\n",
    "    # the input and weights, and then add the bias-values.\n",
    "    layer = tf.matmul(input, weights) + biases\n",
    "\n",
    "    # Use ReLU?\n",
    "    if use_relu:\n",
    "        layer = tf.nn.relu(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_size_flat], name='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, shape=[None, num_classes], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_cls = tf.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv1, weights_conv1 = \\\n",
    "    new_conv_layer(input=x_image,\n",
    "                   num_input_channels=num_channels,\n",
    "                   filter_size=filter_size1,\n",
    "                   num_filters=num_filters1,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu:0' shape=(?, 32, 32, 16) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_conv2, weights_conv2 = \\\n",
    "    new_conv_layer(input=layer_conv1,\n",
    "                   num_input_channels=num_filters1,\n",
    "                   filter_size=filter_size2,\n",
    "                   num_filters=num_filters2,\n",
    "                   use_pooling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_1:0' shape=(?, 16, 16, 36) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_flat, num_features = flatten_layer(layer_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Reshape_1:0' shape=(?, 9216) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc1 = new_fc_layer(input=layer_flat,\n",
    "                         num_inputs=num_features,\n",
    "                         num_outputs=fc_size,\n",
    "                         use_relu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Relu_2:0' shape=(?, 128) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_fc2 = new_fc_layer(input=layer_fc1,\n",
    "                         num_inputs=fc_size,\n",
    "                         num_outputs=num_classes,\n",
    "                         use_relu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(layer_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-28-c6320b202c3b>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=layer_fc2,\n",
    "                                                        labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_random_batch(X,y,batch_size) :\n",
    "    index=random.sample(range(1,y.shape[0]), batch_size)\n",
    "    return X[index], y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Counter for total number of iterations performed so far.\n",
    "total_iterations = 0\n",
    "batch_size=100\n",
    "\n",
    "def optimize(num_iterations):\n",
    "    # Ensure we update the global variable rather than a local copy.\n",
    "    global total_iterations\n",
    "\n",
    "    # Start-time used for printing time-usage below.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i in range(total_iterations,\n",
    "                   total_iterations + num_iterations):\n",
    "\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        x_batch, y_true_batch = get_random_batch(Train_dic['data'],Train_dic['label_OneHot'],batch_size)\n",
    "\n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)\n",
    "\n",
    "        # Print status every 100 iterations.\n",
    "        if i % 100 == 0:\n",
    "            # Calculate the accuracy on the training-set.\n",
    "            acc = session.run(accuracy, feed_dict=feed_dict_train)\n",
    "\n",
    "            # Message for printing.\n",
    "            msg = \"Optimization Iteration: {0:>6}, Training Accuracy: {1:>6.1%}\"\n",
    "\n",
    "            # Print it.\n",
    "            print(msg.format(i + 1, acc))\n",
    "\n",
    "    # Update the total number of iterations performed.\n",
    "    total_iterations += num_iterations\n",
    "\n",
    "    # Ending time.\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Difference between start and end-times.\n",
    "    time_dif = end_time - start_time\n",
    "\n",
    "    # Print the time-usage.\n",
    "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors():\n",
    "    # Use TensorFlow to get a list of boolean values\n",
    "    # whether each test-image has been correctly classified,\n",
    "    # and a list for the predicted class of each image.\n",
    "    correct, cls_pred = session.run([correct_prediction, y_pred_cls],\n",
    "                                    feed_dict=feed_dict_test)\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = Test_dic['data'][incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = Test_dic['label_num'][incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=[num_to_label[i] for i in cls_true[0:9]],\n",
    "                cls_pred=[num_to_label[i] for i in cls_pred[0:9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = Test_dic['label_num']\n",
    "\n",
    "    # Get the predicted classifications for the test-set.\n",
    "    cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true, y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, [num_to_label[i] for i in range(num_classes)])\n",
    "    plt.yticks(tick_marks, [num_to_label[i] for i in range(num_classes)])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feed_dict_test = {x: Test_dic['data'],\n",
    "                  y_true: Test_dic['label_OneHot'],\n",
    "                  y_true_cls: Test_dic['label_num']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 23.4%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:      1, Training Accuracy:  26.0%\n",
      "Time usage: 0:00:03\n"
     ]
    }
   ],
   "source": [
    "optimize(num_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test-set: 23.1%\n"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization Iteration:    101, Training Accuracy:  76.0%\n",
      "Time usage: 0:02:01\n",
      "Accuracy on test-set: 65.3%\n",
      "Optimization Iteration:    201, Training Accuracy:  88.0%\n",
      "Time usage: 0:02:00\n",
      "Accuracy on test-set: 72.6%\n",
      "Optimization Iteration:    301, Training Accuracy:  94.0%\n",
      "Time usage: 0:01:54\n",
      "Accuracy on test-set: 75.2%\n",
      "Optimization Iteration:    401, Training Accuracy:  97.0%\n",
      "Time usage: 0:01:55\n",
      "Accuracy on test-set: 77.6%\n",
      "Optimization Iteration:    501, Training Accuracy:  98.0%\n",
      "Time usage: 0:01:54\n",
      "Accuracy on test-set: 77.9%\n",
      "Optimization Iteration:    601, Training Accuracy: 100.0%\n",
      "Time usage: 0:01:59\n",
      "Accuracy on test-set: 79.5%\n",
      "Optimization Iteration:    701, Training Accuracy: 100.0%\n",
      "Time usage: 0:01:55\n",
      "Accuracy on test-set: 80.5%\n",
      "Optimization Iteration:    801, Training Accuracy: 100.0%\n",
      "Time usage: 0:01:54\n",
      "Accuracy on test-set: 80.2%\n",
      "Optimization Iteration:    901, Training Accuracy: 100.0%\n",
      "Time usage: 0:02:07\n",
      "Accuracy on test-set: 81.5%\n",
      "Optimization Iteration:   1001, Training Accuracy: 100.0%\n",
      "Time usage: 0:02:04\n",
      "Accuracy on test-set: 81.2%\n"
     ]
    }
   ],
   "source": [
    "for i in range(10): \n",
    "    optimize(num_iterations=100) \n",
    "    print_accuracy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
