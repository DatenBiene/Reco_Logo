{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to Learn Neural Network with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Donn√©es "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "imPath = \"Paint_image/logo_drew/\"\n",
    "ls_path = glob(os.path.join(imPath, '*' ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Paint_image/logo_drew\\\\messenger_1.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_10.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_2.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_3.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_4.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_5.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_6.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_7.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_8.png',\n",
       " 'Paint_image/logo_drew\\\\messenger_9.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_1.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_10.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_2.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_3.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_4.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_5.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_6.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_7.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_8.png',\n",
       " 'Paint_image/logo_drew\\\\tinder_9.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_to_label ={'tinder':1,'messenger':2} #Pour labeliser facilement\n",
    "data_base={'data': [], 'label' : [],'nom_label' :[],'image':[]}\n",
    "for file in ls_path:                        #On parcours tous les fichiers                \n",
    "    im = cv2.imread(file,0)                 #On charge l'image\n",
    "    im=255-im                               #On inverse le contrast \n",
    "    im = cv2.resize(im, (8, 8))             #On met au bon format de pixels\n",
    "    name= file.split('\\\\')[1].split('_')[0] #On extrait le type\n",
    "    data_base['data']+=[np.ndarray.flatten(im)]\n",
    "    data_base['label']+=[name_to_label[name]]\n",
    "    data_base['nom_label']+=[name]\n",
    "    data_base['image']+=[im]\n",
    "data_base['data']=np.array(data_base['data'])\n",
    "data_base['label']=np.array(data_base['label'])\n",
    "data_base['nom_label']=np.array(data_base['nom_label'])\n",
    "data_base['image']=np.array(data_base['image'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ..., 255,   0,   0],\n",
       "        [  0,   0,   0, ..., 255,  24,   0],\n",
       "        ...,\n",
       "        [  0,   0,   0, ...,   0,   0,   0],\n",
       "        [  0,   0,   0, ...,  64,   0,   0],\n",
       "        [  0,   0,   0, ...,   0,   0,   0]], dtype=uint8),\n",
       " 'image': array([[[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,  16, ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ...,   4,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ..., 203,  66,   0],\n",
       "         [  0,   0,   0, ..., 255, 192,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ..., 255,  40, 255],\n",
       "         [  0,   0,   0, ..., 255, 255,   0],\n",
       "         [  0,   0,   0, ..., 255,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ..., 255,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0, 154, ...,   0,   8, 255],\n",
       "         [  0,   0,   0, ...,   0, 255,   0],\n",
       "         [  0,   0,   0, ..., 255,  24,   0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,  64, 118, 255],\n",
       "         ...,\n",
       "         [  0,   0, 192, ...,   0,   0,   0],\n",
       "         [  0,   0, 190, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0,   0, ..., 255,   0,   0],\n",
       "         [  0,   0,  42, ..., 215, 171,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0, ...,   0, 255,   0],\n",
       "         [  0,   0,   0, ..., 229, 253,   0],\n",
       "         [  0,   0,   0, ...,  64,   0,   0]],\n",
       " \n",
       "        [[  0,   0,   0, ...,   0,   0,   0],\n",
       "         [  0,   0, 171, ...,  22,   0,   0],\n",
       "         [  0,   0, 255, ..., 192,   0,   0],\n",
       "         ...,\n",
       "         [  0, 140, 213, ..., 255,   0,   0],\n",
       "         [  0,   0, 255, ..., 255,   0,   0],\n",
       "         [  0,   0,   0, ...,   0,   0,   0]]], dtype=uint8),\n",
       " 'label': array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'nom_label': array(['messenger', 'messenger', 'messenger', 'messenger', 'messenger',\n",
       "        'messenger', 'messenger', 'messenger', 'messenger', 'messenger',\n",
       "        'tinder', 'tinder', 'tinder', 'tinder', 'tinder', 'tinder',\n",
       "        'tinder', 'tinder', 'tinder', 'tinder'], dtype='<U9')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_base['image'][1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = data_base['image'][1].shape\n",
    "\n",
    "# The images are stored in one-dimensional arrays of this length.\n",
    "img_size_flat = data_base['image'][1].size\n",
    "\n",
    "# Number of classes, one class for each of 10 digits.\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_images(images, cls_true, cls_pred=None):\n",
    "    assert len(images) == len(cls_true) == 9\n",
    "    \n",
    "    # Create figure with 3x3 sub-plots.\n",
    "    fig, axes = plt.subplots(3, 3)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Plot image.\n",
    "        ax.imshow(images[i].reshape(img_shape), cmap='binary')\n",
    "\n",
    "        # Show true and predicted classes.\n",
    "        if cls_pred is None:\n",
    "            xlabel = \"True: {0}\".format(cls_true[i])\n",
    "        else:\n",
    "            xlabel = \"True: {0}, Pred: {1}\".format(cls_true[i], cls_pred[i])\n",
    "\n",
    "        ax.set_xlabel(xlabel)\n",
    "        \n",
    "        # Remove ticks from the plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVQAAAD5CAYAAAB4Z80xAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a919e085c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first images from the test-set.\n",
    "images = data_base['image'][5:14]\n",
    "\n",
    "# Get the true classes for those images.\n",
    "cls_true = data_base['nom_label'][5:14]\n",
    "\n",
    "# Plot the images and labels using our helper-function above.\n",
    "plot_images(images=images, cls_true=cls_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, img_size_flat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true = tf.placeholder(tf.float32, [None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_true_cls = tf.placeholder(tf.int64, [None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = tf.Variable(tf.zeros([img_size_flat, num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "biases = tf.Variable(tf.zeros([num_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.matmul(x, weights) + biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_cls = tf.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                           labels=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        203,  66,   0,   0,   0,   0,  70, 255, 255, 192,   0,   0,   0,\n",
       "          0, 255,   0,  64, 192,   0,   0,   0,  58, 235,   0,  64, 192,\n",
       "        183,   0,   0,   0,   0,   0, 255,  40, 255,   0,   0,   0,   0,\n",
       "          0, 255, 255,   0,   0,   0,   0,   0,   0, 255,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  24, 140,   0, 118,   0,   0,\n",
       "         34, 247, 255,   0,  10, 255,   0, 255, 255, 233, 199,   0, 255,\n",
       "          0,   0,   0,   0, 255,   0, 255,   0,   0,   0,   0,   0, 255,\n",
       "        255,   6,   0,   0,   0,   0,   0, 255, 112,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 255,\n",
       "          0,   0,   0,   0,   0,   0, 255, 255,   0,   0,   0,   0,   0,\n",
       "         52, 255, 255,   0,   0,   0,   0, 241, 255,  44, 237,   0,   0,\n",
       "        255,   0,   0,   0, 255, 249, 255, 255,   8,   0,   0,   0, 154,\n",
       "         74,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_base['data'][[1,3,5]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= data_base['data']\n",
    "Y= data_base['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Delanoue\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, Y, test_size=0.1,\n",
    "                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(num_iterations):\n",
    "    for i in range(num_iterations):\n",
    "        # Get a batch of training examples.\n",
    "        # x_batch now holds a batch of images and\n",
    "        # y_true_batch are the true labels for those images.\n",
    "        \n",
    "        x_batch = Xtrain\n",
    "        y_true_batch = ytrain\n",
    "        \n",
    "        # Put the batch into a dict with the proper names\n",
    "        # for placeholder variables in the TensorFlow graph.\n",
    "        # Note that the placeholder for y_true_cls is not set\n",
    "        # because it is not used during training.\n",
    "        feed_dict_train = {x: x_batch,\n",
    "                           y_true: y_true_batch}\n",
    "\n",
    "        # Run the optimizer using this batch of training data.\n",
    "        # TensorFlow assigns the variables in feed_dict_train\n",
    "        # to the placeholder variables and then runs the optimizer.\n",
    "        session.run(optimizer, feed_dict=feed_dict_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  12, 255,\n",
       "        255,   0,   0,   0,   0,  42, 255,   0, 215, 171,   0,   0,   0,\n",
       "         62, 255,   0,   0, 255,   0,   0,   0,   0, 255,   0,   0, 255,\n",
       "          0,   0,   0,   0, 255,   0,   0, 255,   0,   0,   0,   0, 255,\n",
       "        192, 229, 253,   0,   0,   0,   0,  64,  64,  64,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "        203,  66,   0,   0,   0,   0,  70, 255, 255, 192,   0,   0,   0,\n",
       "          0, 255,   0,  64, 192,   0,   0,   0,  58, 235,   0,  64, 192,\n",
       "        183,   0,   0,   0,   0,   0, 255,  40, 255,   0,   0,   0,   0,\n",
       "          0, 255, 255,   0,   0,   0,   0,   0,   0, 255,   0,   0]],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict_test = {x: Xtest,\n",
    "                  y_true: ytest,\n",
    "                  y_true_cls: ytest}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_accuracy():\n",
    "    # Use TensorFlow to compute the accuracy.\n",
    "    acc = session.run(accuracy, feed_dict=feed_dict_test)\n",
    "    \n",
    "    # Print the accuracy.\n",
    "    print(\"Accuracy on test-set: {0:.1%}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_confusion_matrix():\n",
    "    # Get the true classifications for the test-set.\n",
    "    cls_true = data.y_test_cls\n",
    "    \n",
    "    # Get the predicted classifications for the test-set.\n",
    "    cls_pred = session.run(y_pred_cls, feed_dict=feed_dict_test)\n",
    "\n",
    "    # Get the confusion matrix using sklearn.\n",
    "    cm = confusion_matrix(y_true=cls_true,\n",
    "                          y_pred=cls_pred)\n",
    "\n",
    "    # Print the confusion matrix as text.\n",
    "    print(cm)\n",
    "\n",
    "    # Plot the confusion matrix as an image.\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "    # Make various adjustments to the plot.\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(num_classes)\n",
    "    plt.xticks(tick_marks, range(num_classes))\n",
    "    plt.yticks(tick_marks, range(num_classes))\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_example_errors():\n",
    "    # Use TensorFlow to get a list of boolean values\n",
    "    # whether each test-image has been correctly classified,\n",
    "    # and a list for the predicted class of each image.\n",
    "    correct, cls_pred = session.run([correct_prediction, y_pred_cls],\n",
    "                                    feed_dict=feed_dict_test)\n",
    "\n",
    "    # Negate the boolean array.\n",
    "    incorrect = (correct == False)\n",
    "    \n",
    "    # Get the images from the test-set that have been\n",
    "    # incorrectly classified.\n",
    "    images = data.x_test[incorrect]\n",
    "    \n",
    "    # Get the predicted classes for those images.\n",
    "    cls_pred = cls_pred[incorrect]\n",
    "\n",
    "    # Get the true classes for those images.\n",
    "    cls_true = data.y_test_cls[incorrect]\n",
    "    \n",
    "    # Plot the first 9 images.\n",
    "    plot_images(images=images[0:9],\n",
    "                cls_true=cls_true[0:9],\n",
    "                cls_pred=cls_pred[0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_weights():\n",
    "    # Get the values for the weights from the TensorFlow variable.\n",
    "    w = session.run(weights)\n",
    "    \n",
    "    # Get the lowest and highest values for the weights.\n",
    "    # This is used to correct the colour intensity across\n",
    "    # the images so they can be compared with each other.\n",
    "    w_min = np.min(w)\n",
    "    w_max = np.max(w)\n",
    "\n",
    "    # Create figure with 3x4 sub-plots,\n",
    "    # where the last 2 sub-plots are unused.\n",
    "    fig, axes = plt.subplots(3, 4)\n",
    "    fig.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # Only use the weights for the first 10 sub-plots.\n",
    "        if i<10:\n",
    "            # Get the weights for the i'th digit and reshape it.\n",
    "            # Note that w.shape == (img_size_flat, 10)\n",
    "            image = w[:, i].reshape(img_shape)\n",
    "\n",
    "            # Set the label for the sub-plot.\n",
    "            ax.set_xlabel(\"Weights: {0}\".format(i))\n",
    "\n",
    "            # Plot the image.\n",
    "            ax.imshow(image, vmin=w_min, vmax=w_max, cmap='seismic')\n",
    "\n",
    "        # Remove ticks from each sub-plot.\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    # Ensure the plot is shown correctly with multiple plots\n",
    "    # in a single Notebook cell.\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2,) for Tensor 'Placeholder_1:0', which has shape '(?, 2)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-6789fcd6b14d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-8e66dc27a46a>\u001b[0m in \u001b[0;36mprint_accuracy\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# Use TensorFlow to compute the accuracy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# Print the accuracy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Delanoue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Delanoue\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1128\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1129\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (2,) for Tensor 'Placeholder_1:0', which has shape '(?, 2)'"
     ]
    }
   ],
   "source": [
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
